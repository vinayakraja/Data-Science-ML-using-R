---
title: 'Chapter 1 : Data Analysis using R'
author: "Vinayak Raja"
date: "Feburary 1, 2018"
output:output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

**R Markdown files** are designed to be used in three ways:

a.)Communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.

b.) For collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).

c.) As an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.

```{r packages, include=TRUE, result=FALSE, message = FALSE	,warning = FALSE }
library(data.table) # best package for reading data in any format( pandas equivalent for some functions in Python )
library(RODBC)# Similar to Pyodbc for connecting to terdata or any DB with ODBC 
library(tcltk)# small applet to create application exampl:-password app
library(sqldf)# manipulating dataframe with sql code if you dont want DPLY
library(dplyr) # data manipulation library ( everything is based on it:- Pandas was inspired by this)
library(ggplot2)# for data visualization ( you can do anything like )
library(MASS) # provides some statistcal functions
library(corrplot)# making coorelation plot 
```

## Major R Packages 

The sheer power of R lies in its incredible packages. In R, most data handling tasks can be performed in 2 ways: Using R packages and R base functions.

**To install a package, simply type:** 'r install.packages("package name")'

**Importing Data:** R offers wide range of packages for importing data available in any format such as .txt, .csv, .json, .sql etc. To import large files of data quickly, it is advisable to install and use data.table, readr, RMySQL, sqldf, jsonlite.

**Data Visualization:** R has in built plotting commands as well. They are good to create simple graphs. But, becomes complex when it comes to creating advanced graphics. Hence, you should install ggplot2.

**Data Manipulation:** R has a fantastic collection of packages for data manipulation. These packages allows you to do basic & advanced computations quickly. These packages are dplyr, plyr, tidyr, lubridate, stringr. 

**Modeling / Machine Learning:** For modeling, caret package in R is powerful enough to cater to every need for creating machine learning model. However, you can install packages algorithms wise such as randomForest, rpart, gbm etc

```{r loading data, include=TRUE, cache = TRUE, message = FALSE	,warning = FALSE }
# Setting the Working directory
setwd("C:\\Users\\vraja\\Desktop\\Vinayak\\Whitepapers\\R MLDatascience")


#loading the data 
pokemon<-fread("https://raw.githubusercontent.com/vinayakraja/Datasets/master/pokemon.csv")
#Reading from computer
#ostk_df<-read.csv("white_csv.csv", stringsAsFactors = FALSE)
```

## Data Types in R

#### R has various type of 'data types' which includes vector (numeric, integer etc), matrices, data frames and list.

Everything you see or create in R is an object. A vector, matrix, data frame, even a variable is an object. R treats it that way. So, R has 5 basic classes of objects. This includes:

* Character( super set of Factors)
* Numeric (Real Numbers)
* Integer (Whole Numbers)
* Complex
* Logical (True / False)

**Vector:** Vector contains object of same class. But, you can mix objects of different classes too. When objects of different classes are mixed in a list, coercion occurs. This effect causes the objects of different types to 'convert' into one class. For example:

*qt <- c("Time", 24, "October", TRUE, 3.33)  #character*

To check the class of any object, use class("vector name") function. class of HP vector:- 'r class$HP'. 

**List:** A list is a special type of vector which contain elements of different data types. For example:

*my_list <- list(22, "ab", TRUE, 1 + 2i)* use this in R console 

**Matrices:** When a vector is introduced with row and column i.e. a dimension attribute, it becomes a matrix. Let's create a matrix of 3 rows and 2 columns:

*my_matrix <- matrix(1:6, nrow=3, ncol=2)* 
The dimensions of a matrix can be obtained using either dim() or attributes() command. Example: 

*dim(my_matrix) or attributes(my_matrix)*

**You can also join two vectors using cbind()( consider them as Join) and rbind()( consider them as union) functions.**

**Data Frame:** This is the most commonly used member of data types family. It is used to store tabular data. It is different from matrix. In a matrix, every element must have same class. But, in a data frame, you can put list of vectors containing different classes.

class of file read in our enviornment : 'r class(pokemon)' , you can see it is dataframe(Mixed vectors). 

## Understanding the data 

##### check dimesions ( number of row & columns) in data set
```{r data exploration1, include=TRUE}
dim(pokemon)
```
#####column name 
```{r data exploration2, include=TRUE}
names(pokemon) 
```
##### check the variables and their types in dataset```
```{r data exploration3, include=TRUE}
str(pokemon)
```
##### Reading the head ( or top 6 rows)
```{r data exploration4, include=TRUE}

head(pokemon)
```
##### getting the summary stats in R 
```{r data exploration5, include=TRUE}
summary(pokemon)
```
##### Finding Missing values 
```{r data exploration6, include=TRUE}
table(is.na(pokemon))
```
##### Getting the missing value count 
```{r data exploration7, include=TRUE}
colSums(is.na(pokemon))
```

### CORRELATION
**The value of CORRELATION COEFFICIENT is always between +1 and -1. To interpret its value, see which of the following values your correlation is closest to:**

> **Exactly -1** A perfect downhill (negative) linear relationship

> **-0.70** A strong downhill (negative) linear relationship

> **-0.50** A moderate downhill (negative) relationship

> **-0.30** A weak downhill (negative) linear relationship

> **0** No linear relationship

> **+0.30** A weak uphill (positive) linear relationship

> **+0.50** A moderate uphill (positive) relationship

> **+0.70** A strong uphill (positive) linear relationship

> **Exactly +1** A perfect uphill (positive) linear relationship

**However, you can take the idea of no linear relationship two ways:**

1. If no relationship at all exists, calculating the correlation doesn't make sense because correlation only applies to linear relationships.

2. If a strong relationship exists but it's not linear, the correlation may be misleading, because in some cases a strong curved relationship exists. That's why it's critical to examine the scatterplot first.

#### Building CORRELATION Plot 
```{r data exploration9, include=TRUE}
poke<- as.data.frame(pokemon) # as Pokemon is data table type ( loaded using  fread)
cor_df <- poke[ sapply(pokemon, is.numeric)] # Fetching only numeric values

corelation<-cor(cor_df)
#Building the Co relatiopn plot 
corrplot(corelation, method="number")
```
**Positive correlations are displayed in blue and negative correlations in red color. Color intensity and the size of the circle are proportional to the correlation coefficients.**

###CONCLUSION

Try similar stuff in Python using this [repo](https://github.com/vinayakraja/Data-Science-ML-using-Python-/blob/master/CHP-1%20Exploratory%20Data%20Analysis%20and%20Python%20intro/Python%20Data%20Science%20-%20Chapter%201%20Intro%20to%20Data%20Analysis%20using%20Python%20.ipynb). Reach me for questions.

- Vinayak Raja
